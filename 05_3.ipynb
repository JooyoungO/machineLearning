{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ8Ww+4o0IYRndJKtlANHv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JooyoungO/machineLearning/blob/main/05_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정형 데이터 vs 비정형 데이터**\n",
        "\n",
        "정형 데이터 : csv 파일처럼 구조를 가지고 있는 데이터\n",
        "\n",
        "비정형 데이터 : 텍스트 데이터, 사진, 디지털 음악 등 구조를 가지고 있지 않은 데이터 (6장)\n",
        "\n",
        "지금까지 배운 머신러닝 알고리즘들은 정형 데이터에 적합\n",
        "\n",
        "  * k - 최근접 이웃, 선형 회귀, 릿지, 라쏘 ..."
      ],
      "metadata": {
        "id": "ppmYIiKTKvVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **앙상블 학습**\n",
        "\n",
        "정형 데이터를 다루는데 가장 뛰어난 성과를 내는 알고리즘\n",
        "\n",
        "대다수의 앙상블 학습 알고리즘은 결정 트리를 기반으로 함\n",
        "\n",
        "# **랜덤 포래스트**\n",
        "\n",
        "앙상블 학습 중 가장 유명하고 안정적인 성능을 제공\n",
        "\n",
        "여러개의 결정 트리를 랜덤하게 만들고 각 결정 트리의 예측을 사용해 최종 예측을 출력\n",
        "어떻게 결정 트리를 랜덤하게 만들것인가 핵심\n",
        "\n",
        "1. 훈련하기 위한 데이터를 랜덤하게 만듦\n",
        "\n",
        "  * 입력한 훈련 데이터에서 랜덤하게 샘플을 추출함\n",
        "\n",
        "  * 중복된 샘플을 추출할 수 있음\n",
        "\n",
        "  * 이렇게 만들어진 샘플을 부트스트랩 샘플 이라 함\n",
        "\n",
        "  * 기본적으로 훈련 세트의 크기와 동일하게 설정됨\n",
        "\n",
        "  ex. 1000개의 샘플로 구성된 훈련 세트가 주어지면 그 훈련 세트로부터 랜덤하게 1000개의 샘플을 중복이 가능하도록 선택\n",
        "\n",
        "2. 부트스트랩 심플로 결정 트리를 훈련\n",
        "\n",
        "  * 각 노드를 분할 할 때 전체 특성 중에서 일부 특성을 무작위로 고른 다음 이 중에서 최선의 분할을 찾음\n",
        "\n",
        "  * RandomForestClassfier 분류 모델은 기본적으로 전체 특성 개수의 제곱근만큼의 특성으로 선택\n",
        "\n",
        "  * RandomForestClassfier 회귀 모델은 전체 특성을 사용\n",
        "\n",
        "3. 정해진 수 만큼 위 과정을 반복"
      ],
      "metadata": {
        "id": "LFzSWKBOLCE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런의 랜덤 포레스트는 기본적으로 100개의 결정 트리를 훈련\n",
        "\n",
        "분류일 때는 각 트리의 클래스별 확률을 평균하여 가장 높은 확률을 가진 클래스를 예측으로 결정\n",
        "\n",
        "회귀일 때는 각 트리의 예측을 평균함\n",
        "\n",
        "랜덤하게 선택한 샘플과 특성을 사용하기 때문에 훈련 세트에 과대적합되는 것을 막아주고 검증 세트와 테스트 세트에서 안정적인 성능을 얻을 수 있음\n",
        "\n",
        "랜덤 포레스트는 누락된 값이 있어도 처리가 가능하다는 장점이 있음"
      ],
      "metadata": {
        "id": "4L_xv4F9MpWl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ktmqwpsrHRZs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTgwsh92Newd",
        "outputId": "23da0b1e-3738-489d-cec3-eb0a01a86c59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9973541965122431 0.8905151032797809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 중요도 출력\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNhGLiKQNidL",
        "outputId": "e7e72073-c5d6-4405-fa7c-80dd118780b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvDInRntNtpu",
        "outputId": "3508fe1f-02b3-4afa-c859-2b95bbaea142"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "oob_score\n",
        "\n",
        "랜덤하게 부트스트랩 샘플을 선택하기 때문에 사용할 수 있는 RandomForestClassifier"
      ],
      "metadata": {
        "id": "1cuLR_yzOB7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **엑스트라 트리**\n",
        "\n",
        "랜덤 포레스트와 비슷하게 동작\n",
        "\n",
        "  * 부트스트랩 샘플을 사용하지 않고, 각 결정 트리를 만들 때 전체 훈련 세트를 사용\n",
        "\n",
        "  * 노드를 분할할 때 가장 좋은 분할을 찾이 않고 랜덤으로 분할함"
      ],
      "metadata": {
        "id": "KujHqM_hOOPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEogl-f4Oe23",
        "outputId": "5a705579-7eae-42df-ff0c-6a420bad6d30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9974503966084433 0.8887848893166506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzT3qQAtOgsO",
        "outputId": "1191819f-afe2-4d98-c7d6-c5740059c1f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **그레이디언트 부스팅**\n",
        "\n",
        "**Bagging vs Boosting**\n",
        "\n",
        "위 두 방법은 베깅 방법임\n",
        "\n",
        "여러 개의 모델을 랜덤하게 만들고 각 ㅁ델의 결과를 종합하여 결과를 출력\n",
        "\n",
        "아래 방법들은 부스팅 방식임\n",
        "\n",
        "모델을 순차적으로 여러개 만들되 이전 모델을 보완한 새로운 모델을 만들고 최종적으로 생성된 모든 모델을 하나로 합침\n",
        "\n",
        "깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식\n",
        "\n",
        "사이킷런에서는 기본적으로 깊이가 3인 결정 트리 100개를 사용\n",
        "\n",
        "깊이가 얕은 결정 트리를 사용하므로 과대적합에 강하고 일반적으로 높은 일반화 성능을 기대할 수 있음\n",
        "\n",
        "---\n",
        "\n",
        "그레이디언트란 이름이 붙은 이유는 경사 하강법을 사용하여 트리를 앙상블에 추가하기 때문\n",
        "\n",
        "\n",
        "분류에서는 로지스틱 손실 함수를 사용\n",
        "\n",
        "회귀애서는 평균 제곱 오차 함수를 사용\n",
        "\n",
        "---\n",
        "\n",
        "경사 하강법이 손실 함수를 산으로 정의하고 가장 낮은 곳을 찾아 내려오는 과정이라면, 그레이디언트 부스팅은 결정 트리를 계속 추가하면서 가장 낮은 곳을 찾아 이동함\n",
        "\n",
        "\n",
        "\n",
        "경사 하강법에서 손실 함수의 낮은 곳으로 천천히 조금씩 이동해야하는 것처럼 그레이디언트 부스팅도 마찬가지이므로 깊이가 얕은 트리를 사용함\n",
        "\n",
        "학습률 매개변수로 속도를 조절함\n",
        "\n",
        "예측에 사용될 데이터가 많은 사용함"
      ],
      "metadata": {
        "id": "GenQZn1lOi0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ci47RTHOv8T",
        "outputId": "c36ea38d-db64-4ffc-d776-f09ff3ae0f37"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그레이디언트 부스팅은 결정 트리의 개수를 늘려도 과대적합에 매우 강함\n",
        "\n",
        "학습률을 증가시ㅣ고 트리의 개수를 늘리면 조금 더 성능이 향상될 수 있음\n",
        "\n",
        "학습률이 0.1이 기본값\n",
        "\n",
        "트리의 개수(n_estimator_)는 100이 기본값"
      ],
      "metadata": {
        "id": "VnsM9bD2Qoek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kZkp_LPOxw6",
        "outputId": "f56d7597-e62e-4f6a-8092-61d735d46431"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9464595437171814 0.8780082549788999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUKxeEiuOy2p",
        "outputId": "8b9e8382-42ec-4711-f2d9-bb64b5366bd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.15872278 0.68010884 0.16116839]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **히스토그램 기반 그레이디언트 부스팅**\n",
        "\n",
        "정형 데이터를 다루는 머신러닝 알고리즘 중에서 가장 인기가 높은 알고리즘\n",
        "\n",
        "입력 특성을 256개의 구간으로 나누므로 노드를 분할할 때 최적의 분할을 매두 빠르게 찾을 수 있음\n",
        "\n",
        "256개의 구간 중에서 하나를 떼어 놓고 누락된 값을 위해서 사용함\n",
        "\n",
        "즉, 어떤 샘플에 누락된 값이 있다면 떼어놓은 구간의 값을 대신 사용함\n",
        "\n",
        "따라서 입력에 누락된 특성이 있더라도 이름 따로 전처리할 필요가 없음\n",
        "\n",
        "히스토그램 :  데이터를 일정한 구간으로 쪼개서 막대그래프로 표현\n",
        "\n",
        "입력 데이터의 각 특성을 256개의 구간으로 나누어 256개의 값으로 변환\n",
        "\n",
        "max_iter : 부스팅 반복 횟수, 성능을 높이려면 이 매개변수를 조절"
      ],
      "metadata": {
        "id": "ZtZ9Spj3RHm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런 1.0 버전 아래에서는 다음 라인의 주석을 해제하고 실행하세요.\n",
        "# from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSDrrdm0R7Jp",
        "outputId": "7598b68f-e162-4a84-9d35-cb83a808249b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "hgb.fit(train_input, train_target)\n",
        "result = permutation_importance(hgb, train_input, train_target, n_repeats=10,\n",
        "                                random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs88S5EDR9S_",
        "outputId": "cd1b8f67-8426-43a2-9e3c-d1c5d8cffff5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08876275 0.23438522 0.08027708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = permutation_importance(hgb, test_input, test_target, n_repeats=10,\n",
        "                                random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1iYsOw2SB5Y",
        "outputId": "bf40712a-5334-4689-9b5b-845eeb11cbd9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05969231 0.20238462 0.049     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hgb.score(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jlNow6HSD0L",
        "outputId": "b8eeea4f-3607-4ccf-da65-a8b1e438db55"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}